{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "project_directory = '..'\n",
    "sys.path.append(os.path.abspath(project_directory))\n",
    "\n",
    "import tinycudann as tcnn\n",
    "import commentjson as ctjs\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import NamedTuple\n",
    "from plyfile import PlyData, PlyElement\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (1270371456.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    pcd_path=f/users/axing2/data/users/axing2/gaussian-splatting/output/sh1/zekun_color4/point_cloud/iteration_31000/point_cloud.ply'\u001b[0m\n\u001b[0m                                                                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "postfixs=['F_4']\n",
    "ntc_conf_paths=['../configs/cache/cache_'+postfix+'.json' for postfix in postfixs]\n",
    "# pcd_path='../test/flame_steak_suite/flame_steak_init/point_cloud/iteration_15000/point_cloud.ply'\n",
    "pcd_path=f\"/users/axing2/data/users/axing2/AT-GS/{sequence}/point_cloud/iteration_31000/point_cloud.ply\"\n",
    "# save_paths=['../ntc/flame_steak_ntc_params_'+postfix+'.pth' for postfix in postfixs]\n",
    "save_paths=['../ntc/zekun_color4_ntc_params_'+postfix+'.pth' for postfix in postfixs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicPointCloud(NamedTuple):\n",
    "    points : np.array\n",
    "    colors : np.array\n",
    "    normals : np.array\n",
    "\n",
    "def fetchXYZ(path):\n",
    "    plydata = PlyData.read(path)\n",
    "    xyz = np.stack((np.asarray(plydata.elements[0][\"x\"]),\n",
    "                    np.asarray(plydata.elements[0][\"y\"]),\n",
    "                    np.asarray(plydata.elements[0][\"z\"])),  axis=1)\n",
    "    return torch.tensor(xyz, dtype=torch.float, device=\"cuda\")\n",
    "\n",
    "def get_xyz_bound(xyz, percentile=80):\n",
    "    ## Hard-code the coordinate of the corners here!!\n",
    "    # return torch.tensor([-20, -15,   5]).cuda(), torch.tensor([15, 10, 23]).cuda()\n",
    "    return torch.tensor([0.4085, 0.3183, 0.1371]).cuda(), torch.tensor([0.5967, 0.6040, 0.5843]).cuda()\n",
    "\n",
    "def get_contracted_xyz(xyz):\n",
    "    xyz_bound_min, xyz_bound_max = get_xyz_bound(xyz, 80)\n",
    "    normalzied_xyz=(xyz-xyz_bound_min)/(xyz_bound_max-xyz_bound_min)\n",
    "    return normalzied_xyz\n",
    "\n",
    "@torch.compile\n",
    "def quaternion_multiply(a, b):\n",
    "    a_norm=nn.functional.normalize(a)\n",
    "    b_norm=nn.functional.normalize(b)\n",
    "    w1, x1, y1, z1 = a_norm[:, 0], a_norm[:, 1], a_norm[:, 2], a_norm[:, 3]\n",
    "    w2, x2, y2, z2 = b_norm[:, 0], b_norm[:, 1], b_norm[:, 2], b_norm[:, 3]\n",
    "\n",
    "    w = w1 * w2 - x1 * x2 - y1 * y2 - z1 * z2\n",
    "    x = w1 * x2 + x1 * w2 + y1 * z2 - z1 * y2\n",
    "    y = w1 * y2 + y1 * w2 + z1 * x2 - x1 * z2\n",
    "    z = w1 * z2 + z1 * w2 + x1 * y2 - y1 * x2\n",
    "\n",
    "    return torch.stack([w, x, y, z], dim=1)\n",
    "\n",
    "def quaternion_loss(q1, q2):\n",
    "    cos_theta = F.cosine_similarity(q1, q2, dim=1)\n",
    "    cos_theta = torch.clamp(cos_theta, -1+1e-7, 1-1e-7)\n",
    "    return 1-torch.pow(cos_theta, 2).mean()\n",
    "\n",
    "def l1loss(network_output, gt):\n",
    "    return torch.abs((network_output - gt)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ntcs=[]\n",
    "for ntc_conf_path in ntc_conf_paths:    \n",
    "    with open(ntc_conf_path) as ntc_conf_file:\n",
    "        ntc_conf = ctjs.load(ntc_conf_file)\n",
    "    ntc=tcnn.NetworkWithInputEncoding(n_input_dims=3, n_output_dims=8, encoding_config=ntc_conf[\"encoding\"], network_config=ntc_conf[\"network\"]).to(torch.device(\"cuda\"))\n",
    "    ntc_optimizer = torch.optim.Adam(ntc.parameters(), lr=1e-4)\n",
    "    xyz=fetchXYZ(pcd_path)\n",
    "    normalzied_xyz=get_contracted_xyz(xyz)\n",
    "    mask = (normalzied_xyz >= 0) & (normalzied_xyz <= 1)\n",
    "    mask = mask.all(dim=1)\n",
    "    ntc_inputs=torch.cat([normalzied_xyz[mask]],dim=-1)\n",
    "    noisy_inputs = ntc_inputs + 0.01 * torch.rand_like(ntc_inputs)\n",
    "    d_xyz_gt=torch.tensor([0.,0.,0.]).cuda()\n",
    "    d_rot_gt=torch.tensor([1.,0.,0.,0.]).cuda()\n",
    "    dummy_gt=torch.tensor([1.]).cuda()\n",
    "    def cacheloss(resi):\n",
    "        masked_d_xyz=resi[:,:3]\n",
    "        masked_d_rot=resi[:,3:7]\n",
    "        masked_dummy=resi[:,7:8]\n",
    "        loss_xyz=l1loss(masked_d_xyz,d_xyz_gt)\n",
    "        loss_rot=quaternion_loss(masked_d_rot,d_rot_gt)\n",
    "        loss_dummy=l1loss(masked_dummy,dummy_gt)\n",
    "        loss=loss_xyz+loss_rot+loss_dummy\n",
    "        return loss\n",
    "    for iteration in range(0,3000):      \n",
    "        ntc_inputs_w_noisy = torch.cat([noisy_inputs, ntc_inputs, torch.rand_like(ntc_inputs)],dim=0)  \n",
    "        ntc_output=ntc(ntc_inputs_w_noisy) #.to(torch.float64)\n",
    "        loss=cacheloss(ntc_output)\n",
    "        if iteration % 100 ==0:\n",
    "            print(loss)\n",
    "        loss.backward()\n",
    "        ntc_optimizer.step()\n",
    "        ntc_optimizer.zero_grad(set_to_none = True)\n",
    "    ntcs.append(ntc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../ntc/zekun_color4_ntc_params_F_4.pth\n"
     ]
    }
   ],
   "source": [
    "from ntc import NeuralTransformationCache\n",
    "for idx, save_path in enumerate(save_paths):\n",
    "    print(save_path)\n",
    "    ntc=NeuralTransformationCache(ntcs[idx],get_xyz_bound(xyz)[0],get_xyz_bound(xyz)[1])\n",
    "    torch.save(ntc.state_dict(),save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
